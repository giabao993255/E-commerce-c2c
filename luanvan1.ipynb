{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "luanvan1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giabao993255/luanvanhk2/blob/main/luanvan1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tinh chỉnh LayoutLM bằng tập dữ liệu SROIE\n",
        "Sổ tay này là nỗ lực của tôi trong việc tinh chỉnh mô hình LayoutLM bằng cách sử dụng tập dữ liệu SROIE để trích xuất thông tin. Mô hình được trình bày trong bài báo \"[LayoutLM: Đào tạo trước về Văn bản và Bố cục để Hiểu Hình ảnh Tài liệu] (https://arxiv.org/abs/1912.13318)\" của Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei và Ming Zhou và máy tính xách tay đã được truyền cảm hứng rất nhiều từ máy tính xách tay \"ruifcruz\" của người dùng Github có tiêu đề \"Tinh chỉnh SROIE trên LayoutLM\".\n",
        "- LayoutLM Github repo [tại đây] (https://github.com/microsoft/unilm/tree/master/layoutlm).\n",
        "- Bộ dữ liệu được lấy từ cuộc thi ICDAR 2019 SROIE [tại đây] (https://rrc.cvc.uab.es/?ch=13).\n",
        "- \"Tinh chỉnh SROIE trên LayoutLM\" của ruifcruz [tại đây] (https://github.com/ruifcruz/sroie-on-layoutlm).\n",
        "\n",
        "## Ghi chú:\n",
        "- Máy tính xách tay đang sử dụng tập lệnh tiền xử lý được bao gồm trong repo của mô hình [tại đây] (https://github.com/microsoft/unilm/tree/master/layoutlm/examples/seq_labeling) ban đầu được sử dụng để tinh chỉnh tập dữ liệu FUNSD. Chúng ta có thể đào tạo trên tập dữ liệu SROIE với cùng một tập lệnh vì nó dành cho việc ghi nhãn trình tự.\n",
        "- Các tác giả ban đầu của mô hình nhận được điểm F1 ** 0,946 ** (sử dụng mô hình cơ sở) và điểm tối đa tôi nhận được là điểm F1 ** 0,957 ** (10 kỷ nguyên). Đây là một sự cải thiện so với điểm của ruifcruz, bởi vì tôi cũng bao gồm nhãn \"địa chỉ công ty\". Đó cũng là một sự cải thiện về điểm số của các tác giả và lý do cho điều đó, như được giải thích bởi ruifcruz, có thể là:\n",
        "  - Các siêu tham số khác nhau,\n",
        "  - OCR chất lượng - các tác giả không sử dụng bản quét SROIE OCR mà tạo ra bản quét của riêng họ,\n",
        "  - tiền xử lý tốt hơn\n",
        "  "
      ],
      "metadata": {
        "id": "EiEEZVWvUcBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Xử lý trước tập dữ liệu\n",
        "Trước khi tinh chỉnh mô hình, chúng tôi phải xử lý trước tập dữ liệu SROIE có thể tải xuống từ [tại đây] (https://drive.google.com/drive/folders/1ShItNWXyiY1tFDM5W02bceHuJjyeeJl2). Tập dữ liệu chứa nhiều thư mục con, vì cuộc thi được chia thành ba nhiệm vụ ** Bản địa hóa văn bản, Nhận dạng ký tự quang học (OCR) ** và ** Trích xuất thông tin (IE) ** và một số thư mục dành cho nhiệm vụ cụ thể của chúng. Vì mục đích của chúng tôi, chúng tôi chỉ quan tâm đến nhiệm vụ cuối cùng, vì vậy các thư mục dành cho nó là:\n",
        "- ** 0325updated.task1train (626p) ** - chứa hình ảnh biên lai (.jpg) và các hộp giới hạn OCR'd tương ứng và văn bản (.txt)\n",
        "- ** 0325updated.task2train (626p) ** - chứa văn bản được gắn nhãn (.txt) ở định dạng JSON.\n",
        "\n",
        "Nhưng đối với sổ ghi chép này, tôi thực sự sẽ sử dụng một phiên bản có tổ chức của bộ datset có sẵn công khai mà tôi đã tạo. Tập dữ liệu được tổ chức theo cách dễ hiểu, không có bất kỳ tệp trùng lặp nào và tôi cũng đã thêm một tập hợp con thử nghiệm không có trong liên kết trước đó. Tập dữ liệu có sẵn [tại đây] (https://www.kaggle.com/urbikn/sroie-datasetv2)."
      ],
      "metadata": {
        "id": "O4tunUBNUcB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import json \n",
        "import random\n",
        "from pathlib import Path\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from IPython.display import display\n",
        "import matplotlib\n",
        "from matplotlib import pyplot, patches"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-12-12T11:14:18.135016Z",
          "iopub.execute_input": "2021-12-12T11:14:18.135406Z",
          "iopub.status.idle": "2021-12-12T11:14:18.302977Z",
          "shell.execute_reply.started": "2021-12-12T11:14:18.135322Z",
          "shell.execute_reply": "2021-12-12T11:14:18.302211Z"
        },
        "trusted": true,
        "id": "V-ZFl6JvUcB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chuẩn bị tập dữ liệu\n",
        "Vị trí của tập dữ liệu SROIE và tên của tệp ví dụ được sử dụng cho mục đích trình diễn"
      ],
      "metadata": {
        "id": "LpnnDDdNUcB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sroie_folder_path = Path('/kaggle/input/sroie-datasetv2/SROIE2019')\n",
        "example_file = Path('X51005365187.txt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:06.387486Z",
          "iopub.execute_input": "2021-12-12T11:18:06.387809Z",
          "iopub.status.idle": "2021-12-12T11:18:06.391855Z",
          "shell.execute_reply.started": "2021-12-12T11:18:06.387779Z",
          "shell.execute_reply": "2021-12-12T11:18:06.390874Z"
        },
        "trusted": true,
        "id": "LzdMNN-fUcB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đọc các từ và hộp giới hạn\n",
        "Vì vậy, bước đầu tiên là đọc dữ liệu OCR, trong đó mỗi dòng trong tệp bao gồm một nhóm từ và một hộp giới hạn xác định chúng. Tất cả những gì chúng ta phải làm là đọc tệp, loại bỏ các điểm không cần thiết trong hộp giới hạn (vì mô hình chỉ yêu cầu các điểm trên cùng bên trái và dưới cùng bên phải) và lưu nó trong Pandas Dataframe."
      ],
      "metadata": {
        "id": "WCitpsFvUcB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_bbox_and_words(path: Path):\n",
        "  bbox_and_words_list = []\n",
        "\n",
        "  with open(path, 'r', errors='ignore') as f:\n",
        "    for line in f.read().splitlines():\n",
        "      if len(line) == 0:\n",
        "        continue\n",
        "        \n",
        "      split_lines = line.split(\",\")\n",
        "\n",
        "      bbox = np.array(split_lines[0:8], dtype=np.int32)\n",
        "      text = \",\".join(split_lines[8:])\n",
        "\n",
        "      # From the splited line we save (filename, [bounding box points], text line).\n",
        "      # The filename will be useful in the future\n",
        "      bbox_and_words_list.append([path.stem, *bbox, text])\n",
        "    \n",
        "  dataframe = pd.DataFrame(bbox_and_words_list, columns=['filename', 'x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'line'], dtype=np.int16)\n",
        "  dataframe = dataframe.drop(columns=['x1', 'y1', 'x3', 'y3'])\n",
        "\n",
        "  return dataframe\n",
        "\n",
        "\n",
        "# Example usage\n",
        "bbox_file_path = sroie_folder_path / \"test/box\" / example_file\n",
        "print(\"== File content ==\")\n",
        "!head -n 5 \"{bbox_file_path}\"\n",
        "\n",
        "bbox = read_bbox_and_words(path=bbox_file_path)\n",
        "print(\"\\n== Dataframe ==\")\n",
        "bbox.head(5)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:07.357228Z",
          "iopub.execute_input": "2021-12-12T11:18:07.357591Z",
          "iopub.status.idle": "2021-12-12T11:18:08.065093Z",
          "shell.execute_reply.started": "2021-12-12T11:18:07.35756Z",
          "shell.execute_reply": "2021-12-12T11:18:08.064219Z"
        },
        "trusted": true,
        "id": "aVySg21PUcB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đọc tệp thực thể\n",
        "Bây giờ chúng ta cần đọc tệp thực thể để biết những gì cần gắn nhãn trong văn bản của chúng ta."
      ],
      "metadata": {
        "id": "xBvgcO-aUcCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_entities(path: Path):\n",
        "  with open(path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  dataframe = pd.DataFrame([data])\n",
        "  return dataframe\n",
        "\n",
        "\n",
        "# Example usage\n",
        "entities_file_path = sroie_folder_path /  \"test/entities\" / example_file\n",
        "print(\"== File content ==\")\n",
        "!head \"{entities_file_path}\"\n",
        "\n",
        "entities = read_entities(path=entities_file_path)\n",
        "print(\"\\n\\n== Dataframe ==\")\n",
        "entities"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:11.603217Z",
          "iopub.execute_input": "2021-12-12T11:18:11.60356Z",
          "iopub.status.idle": "2021-12-12T11:18:12.283106Z",
          "shell.execute_reply.started": "2021-12-12T11:18:11.603528Z",
          "shell.execute_reply": "2021-12-12T11:18:12.28234Z"
        },
        "trusted": true,
        "id": "3TAMn6TzUcCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gán nhãn cho các từ bằng cách sử dụng dữ liệu thực thể\n",
        "Chúng ta có các từ / dòng và thực thể, bây giờ chúng ta chỉ cần kết hợp chúng lại với nhau bằng cách gắn nhãn các dòng của chúng ta bằng cách sử dụng các giá trị thực thể. Chúng tôi sẽ thực hiện điều đó bằng cách kết hợp các chuỗi con với các giá trị thực thể với các dòng và nếu chúng không khớp với một kiểm tra độ tương đồng bằng cách sử dụng pythons _difflib.SequenceMatcher_ và chỉ định bất kỳ thứ gì cao hơn so với dự đoán 0,8 (80%).\n",
        "\n",
        "** Nhãn \"O\" ** sẽ xác định tất cả các từ không được gắn nhãn của chúng ta trong bước gán, vì chúng ta bắt buộc phải gắn nhãn cho mọi thứ."
      ],
      "metadata": {
        "id": "c-NAJBPQUcCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign a label to the line by checking the similarity\n",
        "# of the line and all the entities\n",
        "def assign_line_label(line: str, entities: pd.DataFrame):\n",
        "    line_set = line.replace(\",\", \"\").strip().split()\n",
        "    for i, column in enumerate(entities):\n",
        "        entity_values = entities.iloc[0, i].replace(\",\", \"\").strip()\n",
        "        entity_set = entity_values.split()\n",
        "        \n",
        "        \n",
        "        matches_count = 0\n",
        "        for l in line_set:\n",
        "            if any(SequenceMatcher(a=l, b=b).ratio() > 0.8 for b in entity_set):\n",
        "                matches_count += 1\n",
        "            \n",
        "            if (column.upper() == 'ADDRESS' and (matches_count / len(line_set)) >= 0.5) or \\\n",
        "               (column.upper() != 'ADDRESS' and (matches_count == len(line_set))) or \\\n",
        "               matches_count == len(entity_set):\n",
        "                return column.upper()\n",
        "\n",
        "    return \"O\"\n",
        "\n",
        "\n",
        "line = bbox.loc[1,\"line\"]\n",
        "label = assign_line_label(line, entities)\n",
        "print(\"Line:\", line)\n",
        "print(\"Assigned label:\", label)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:16.400728Z",
          "iopub.execute_input": "2021-12-12T11:18:16.401102Z",
          "iopub.status.idle": "2021-12-12T11:18:16.413241Z",
          "shell.execute_reply.started": "2021-12-12T11:18:16.401056Z",
          "shell.execute_reply": "2021-12-12T11:18:16.412269Z"
        },
        "trusted": true,
        "id": "eheggtWxUcCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Với một chức năng có thể xử lý việc ghi nhãn các dòng của chúng tôi, chúng tôi sẽ tạo một chức năng khác để gắn nhãn tất cả các dòng của chúng tôi trong một DataFrame (vì vậy một biên nhận).\n",
        "\n",
        "Đơn giản như điều này có thể xảy ra, vấn đề nảy sinh khi chúng ta nhận được các dòng mà tất cả sẽ vượt qua cùng một đối sánh, như ** TOTAL ** chẳng hạn; biên lai có thể chỉ có một mặt hàng trên đó và giá của nó có thể bằng với tổng cuối cùng, do đó, các nhãn trùng lặp. Hoặc có thể một phần của địa chỉ cũng có ở cuối biên nhận.\n",
        "\n",
        "Để bỏ qua các ví dụ như vậy, tôi đã viết các quy tắc đơn giản được mã hóa cứng để chỉ định * tổng số * và * ngày * cho chỉ các hộp giới hạn lớn nhất mà nó có thể tìm thấy (dựa trên khu vực của nó) và không cho phép chỉ định địa chỉ sau ngày hoặc tổng số."
      ],
      "metadata": {
        "id": "4y7f6_XtUcCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_labels(words: pd.DataFrame, entities: pd.DataFrame):\n",
        "    max_area = {\"TOTAL\": (0, -1), \"DATE\": (0, -1)}  # Value, index\n",
        "    already_labeled = {\"TOTAL\": False,\n",
        "                       \"DATE\": False,\n",
        "                       \"ADDRESS\": False,\n",
        "                       \"COMPANY\": False,\n",
        "                       \"O\": False\n",
        "    }\n",
        "\n",
        "    # Go through every line in $words and assign it a label\n",
        "    labels = []\n",
        "    for i, line in enumerate(words['line']):\n",
        "        label = assign_line_label(line, entities)\n",
        "\n",
        "        already_labeled[label] = True\n",
        "        if (label == \"ADDRESS\" and already_labeled[\"TOTAL\"]) or \\\n",
        "           (label == \"COMPANY\" and (already_labeled[\"DATE\"] or already_labeled[\"TOTAL\"])):\n",
        "            label = \"O\"\n",
        "\n",
        "        # Assign to the largest bounding box\n",
        "        if label in [\"TOTAL\", \"DATE\"]:\n",
        "            x0_loc = words.columns.get_loc(\"x0\")\n",
        "            bbox = words.iloc[i, x0_loc:x0_loc+4].to_list()\n",
        "            area = (bbox[2] - bbox[0]) + (bbox[3] - bbox[1])\n",
        "\n",
        "            if max_area[label][0] < area:\n",
        "                max_area[label] = (area, i)\n",
        "\n",
        "            label = \"O\"\n",
        "\n",
        "        labels.append(label)\n",
        "\n",
        "    labels[max_area[\"DATE\"][1]] = \"DATE\"\n",
        "    labels[max_area[\"TOTAL\"][1]] = \"TOTAL\"\n",
        "\n",
        "    words[\"label\"] = labels\n",
        "    return words\n",
        "\n",
        "\n",
        "# Example usage\n",
        "bbox_labeled = assign_labels(bbox, entities)\n",
        "bbox_labeled.head(15)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:28.086228Z",
          "iopub.execute_input": "2021-12-12T11:18:28.086631Z",
          "iopub.status.idle": "2021-12-12T11:18:28.175897Z",
          "shell.execute_reply.started": "2021-12-12T11:18:28.086597Z",
          "shell.execute_reply": "2021-12-12T11:18:28.174975Z"
        },
        "trusted": true,
        "id": "P1dqqW7_UcCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chia từ\n",
        "Đối với phần cuối cùng, chúng tôi chia các dòng thành các mã thông báo riêng biệt với các hộp giới hạn của riêng chúng.\n",
        "\n",
        "Tách các hộp giới hạn dựa trên độ dài của từ có lẽ không phải là cách tốt nhất, nhưng nó đủ tốt."
      ],
      "metadata": {
        "id": "cwk0MfXfUcCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_line(line: pd.Series):\n",
        "  line_copy = line.copy()\n",
        "\n",
        "  line_str = line_copy.loc[\"line\"]\n",
        "  words = line_str.split(\" \")\n",
        "\n",
        "  # Filter unwanted tokens\n",
        "  words = [word for word in words if len(word) >= 1]\n",
        "\n",
        "  x0, y0, x2, y2 = line_copy.loc[['x0', 'y0', 'x2', 'y2']]\n",
        "  bbox_width = x2 - x0\n",
        "  \n",
        "\n",
        "  new_lines = []\n",
        "  for index, word in enumerate(words):\n",
        "    x2 = x0 + int(bbox_width * len(word)/len(line_str))\n",
        "    line_copy.at['x0', 'x2', 'line'] = [x0, x2, word]\n",
        "    new_lines.append(line_copy.to_list())\n",
        "    x0 = x2 + 5 \n",
        "\n",
        "  return new_lines\n",
        "\n",
        "\n",
        "# Example usage\n",
        "new_lines = split_line(bbox_labeled.loc[1])\n",
        "print(\"Original row:\")\n",
        "display(bbox_labeled.loc[1:1,:])\n",
        "\n",
        "print(\"Splitted row:\")\n",
        "pd.DataFrame(new_lines, columns=bbox_labeled.columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:34.635841Z",
          "iopub.execute_input": "2021-12-12T11:18:34.636237Z",
          "iopub.status.idle": "2021-12-12T11:18:34.670242Z",
          "shell.execute_reply.started": "2021-12-12T11:18:34.636199Z",
          "shell.execute_reply": "2021-12-12T11:18:34.669336Z"
        },
        "trusted": true,
        "id": "M4y9HXadUcCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Để tất cả chúng cùng nhau\n",
        "Chúng tôi đã xác định tất cả các chức năng của mình, bây giờ chúng tôi chỉ cần sử dụng chúng trên mọi tệp và chuyển đổi tập dữ liệu thành một định dạng mà tập lệnh / mô hình có thể phân tích cú pháp."
      ],
      "metadata": {
        "id": "n00eH1lIUcCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter\n",
        "def dataset_creator(folder: Path):\n",
        "  bbox_folder = folder / 'box'\n",
        "  entities_folder = folder / 'entities'\n",
        "  img_folder = folder / 'img'\n",
        "\n",
        "  # Sort by filename so that when zipping them together\n",
        "  # we don't get some other file (just in case)\n",
        "  entities_files = sorted(entities_folder.glob(\"*.txt\"))\n",
        "  bbox_files = sorted(bbox_folder.glob(\"*.txt\"))\n",
        "  img_files = sorted(img_folder.glob(\"*.jpg\"))\n",
        "\n",
        "  data = []\n",
        "\n",
        "  print(\"Reading dataset:\")\n",
        "  for bbox_file, entities_file, img_file in tqdm(zip(bbox_files, entities_files, img_files), total=len(bbox_files)):            \n",
        "    # Read the files\n",
        "    bbox = read_bbox_and_words(bbox_file)\n",
        "    entities = read_entities(entities_file)\n",
        "    image = Image.open(img_file)\n",
        "\n",
        "    # Assign labels to lines in bbox using entities\n",
        "    bbox_labeled = assign_labels(bbox, entities)\n",
        "    del bbox\n",
        "\n",
        "    # Split lines into separate tokens\n",
        "    new_bbox_l = []\n",
        "    for index, row in bbox_labeled.iterrows():\n",
        "      new_bbox_l += split_line(row)\n",
        "    new_bbox = pd.DataFrame(new_bbox_l, columns=bbox_labeled.columns, dtype=np.int16)\n",
        "    del bbox_labeled\n",
        "\n",
        "\n",
        "    # Do another label assignment to keep the labeling more precise \n",
        "    for index, row in new_bbox.iterrows():\n",
        "      label = row['label']\n",
        "\n",
        "      if label != \"O\":\n",
        "        entity_values = entities.iloc[0, entities.columns.get_loc(label.lower())]\n",
        "        entity_set = entity_values.split()\n",
        "        \n",
        "        if any(SequenceMatcher(a=row['line'], b=b).ratio() > 0.7 for b in entity_set):\n",
        "            label = \"S-\" + label\n",
        "        else:\n",
        "            label = \"O\"\n",
        "      \n",
        "      new_bbox.at[index, 'label'] = label\n",
        "\n",
        "    width, height = image.size\n",
        "  \n",
        "    data.append([new_bbox, width, height])\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:39.093554Z",
          "iopub.execute_input": "2021-12-12T11:18:39.0939Z",
          "iopub.status.idle": "2021-12-12T11:18:39.104825Z",
          "shell.execute_reply.started": "2021-12-12T11:18:39.093869Z",
          "shell.execute_reply": "2021-12-12T11:18:39.103773Z"
        },
        "trusted": true,
        "id": "nHAgPh52UcCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vì tập dữ liệu có hai thư mục, một thư mục dùng để huấn luyện mô hình và một thư mục để kiểm tra hiệu suất của nó, chúng ta có thể sử dụng cùng một tập lệnh để đọc cả hai và lưu chúng trong các biến được tôn trọng của chúng."
      ],
      "metadata": {
        "id": "WgCIshvyUcCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = dataset_creator(sroie_folder_path / 'train')\n",
        "dataset_test = dataset_creator(sroie_folder_path / 'test')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:18:42.296137Z",
          "iopub.execute_input": "2021-12-12T11:18:42.296503Z",
          "iopub.status.idle": "2021-12-12T11:21:02.892877Z",
          "shell.execute_reply.started": "2021-12-12T11:18:42.296471Z",
          "shell.execute_reply": "2021-12-12T11:21:02.892039Z"
        },
        "trusted": true,
        "id": "rRYMKxirUcCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viết tập dữ liệu đã chuyển đổi\n",
        "Bây giờ chúng tôi đã chuyển đổi tập dữ liệu của mình thành một định dạng mà mô hình có thể hiểu để đào tạo, chúng tôi cần lưu mọi thứ vào tệp."
      ],
      "metadata": {
        "id": "SvknozWKUcCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Xác định chức năng viết\n",
        "Chúng tôi sẽ sử dụng chức năng tương tự để ghi vào tệp tàu và tệp thử nghiệm.\n",
        "\n",
        "Chức năng chuẩn hóa có nghĩa là chuẩn hóa các điểm hộp giới hạn trong một phạm vi [0,1000] bằng cách sử dụng chiều rộng và chiều cao của hình ảnh biên lai [\\ [source \\]] (https://huggingface.co/transformers/model_doc/ layoutlm.html # tổng quan)."
      ],
      "metadata": {
        "id": "BQmIJqR2UcCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(points: list, width: int, height: int) -> list:\n",
        "  x0, y0, x2, y2 = [int(p) for p in points]\n",
        "  \n",
        "  x0 = int(1000 * (x0 / width))\n",
        "  x2 = int(1000 * (x2 / width))\n",
        "  y0 = int(1000 * (y0 / height))\n",
        "  y2 = int(1000 * (y2 / height))\n",
        "\n",
        "  return [x0, y0, x2, y2]\n",
        "\n",
        "\n",
        "def write_dataset(dataset: list, output_dir: Path, name: str):\n",
        "  print(f\"Writing {name}ing dataset:\")\n",
        "  with open(output_dir / f\"{name}.txt\", \"w+\", encoding=\"utf8\") as file, \\\n",
        "       open(output_dir / f\"{name}_box.txt\", \"w+\", encoding=\"utf8\") as file_bbox, \\\n",
        "       open(output_dir / f\"{name}_image.txt\", \"w+\", encoding=\"utf8\") as file_image:\n",
        "\n",
        "      # Go through each dataset\n",
        "      for datas in tqdm(dataset, total=len(dataset)):\n",
        "        data, width, height = datas\n",
        "        \n",
        "        filename = data.iloc[0, data.columns.get_loc('filename')]\n",
        "\n",
        "        # Go through every row in dataset\n",
        "        for index, row in data.iterrows():\n",
        "          bbox = [int(p) for p in row[['x0', 'y0', 'x2', 'y2']]]\n",
        "          normalized_bbox = normalize(bbox, width, height)\n",
        "\n",
        "          file.write(\"{}\\t{}\\n\".format(row['line'], row['label']))\n",
        "          file_bbox.write(\"{}\\t{} {} {} {}\\n\".format(row['line'], *normalized_bbox))\n",
        "          file_image.write(\"{}\\t{} {} {} {}\\t{} {}\\t{}\\n\".format(row['line'], *bbox, width, height, filename))\n",
        "\n",
        "        # Write a second newline to separate dataset from others\n",
        "        file.write(\"\\n\")\n",
        "        file_bbox.write(\"\\n\")\n",
        "        file_image.write(\"\\n\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:21:08.276327Z",
          "iopub.execute_input": "2021-12-12T11:21:08.276673Z",
          "iopub.status.idle": "2021-12-12T11:21:08.289608Z",
          "shell.execute_reply.started": "2021-12-12T11:21:08.276642Z",
          "shell.execute_reply": "2021-12-12T11:21:08.288227Z"
        },
        "trusted": true,
        "id": "H-4vV5WZUcCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_directory = Path('/kaggle/working','dataset')\n",
        "\n",
        "dataset_directory.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "write_dataset(dataset_train, dataset_directory, 'train')\n",
        "write_dataset(dataset_test, dataset_directory, 'test')\n",
        "\n",
        "# Creating the 'labels.txt' file to the the model what categories to predict.\n",
        "labels = ['COMPANY', 'DATE', 'ADDRESS', 'TOTAL']\n",
        "IOB_tags = ['S']\n",
        "with open(dataset_directory / 'labels.txt', 'w') as f:\n",
        "  for tag in IOB_tags:\n",
        "    for label in labels:\n",
        "      f.write(f\"{tag}-{label}\\n\")\n",
        "  # Writes in the last label O - meant for all non labeled words\n",
        "  f.write(\"O\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:21:10.631022Z",
          "iopub.execute_input": "2021-12-12T11:21:10.631374Z",
          "iopub.status.idle": "2021-12-12T11:22:09.128001Z",
          "shell.execute_reply.started": "2021-12-12T11:21:10.631331Z",
          "shell.execute_reply": "2021-12-12T11:22:09.127341Z"
        },
        "trusted": true,
        "id": "gCUsjryiUcCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Tinh chỉnh LayoutLM\n",
        "Chúng tôi đã tải xuống và chuyển đổi tập dữ liệu của mình thành một tập hợp có thể đào tạo và kiểm tra được, bây giờ chúng tôi có thể bắt đầu tinh chỉnh mô hình.\n",
        "\n",
        "## Tải xuống mô hình\n",
        "Đầu tiên, chúng tôi sẽ sao chép dự án LayoutLM Github chứa tập lệnh để tinh chỉnh mô hình của chúng tôi."
      ],
      "metadata": {
        "id": "YGxUg_E8UcCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "git clone https://github.com/microsoft/unilm.git\n",
        "cd unilm/layoutlm/deprecated\n",
        "pip install ."
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2021-12-12T11:23:10.010517Z",
          "iopub.execute_input": "2021-12-12T11:23:10.01088Z",
          "iopub.status.idle": "2021-12-12T11:23:29.985122Z",
          "shell.execute_reply.started": "2021-12-12T11:23:10.010849Z",
          "shell.execute_reply": "2021-12-12T11:23:29.984339Z"
        },
        "trusted": true,
        "id": "vLyH6OplUcCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "pNzTK9Z9UcCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_folder_input= sroie_folder_path / Path('layoutlm-base-uncased') # Define it so we can copy it into our working directory\n",
        "\n",
        "pretrained_model_folder=Path('/kaggle/working/layoutlm-base-uncased/') \n",
        "label_file=Path(dataset_directory, \"labels.txt\")\n",
        "\n",
        "# Move to the script directory\n",
        "os.chdir(\"/kaggle/working/unilm/layoutlm/deprecated/examples/seq_labeling\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:24:01.343371Z",
          "iopub.execute_input": "2021-12-12T11:24:01.343723Z",
          "iopub.status.idle": "2021-12-12T11:24:01.350512Z",
          "shell.execute_reply.started": "2021-12-12T11:24:01.343691Z",
          "shell.execute_reply": "2021-12-12T11:24:01.348787Z"
        },
        "trusted": true,
        "id": "QRsLLcktUcCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đầu tiên, tôi sẽ sao chép mô hình cơ sở được đào tạo trước vào thư mục làm việc của chúng tôi để thay đổi tệp cấu hình của nó. Tôi chỉ thay đổi số lượng tiêu đề chú ý từ ** 16 ** thành ** 12 **, vì đó là kích thước ban đầu."
      ],
      "metadata": {
        "id": "iOz-SQzwUcCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -r \"{pretrained_model_folder_input}\" \"{pretrained_model_folder}\"\n",
        "! sed -i 's/\"num_attention_heads\": 16,/\"num_attention_heads\": 12,/' \"{pretrained_model_folder}/\"config.json"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:24:03.066573Z",
          "iopub.execute_input": "2021-12-12T11:24:03.066912Z",
          "iopub.status.idle": "2021-12-12T11:24:07.421739Z",
          "shell.execute_reply.started": "2021-12-12T11:24:03.066879Z",
          "shell.execute_reply": "2021-12-12T11:24:07.420566Z"
        },
        "trusted": true,
        "id": "Z76KMvWyUcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat \"/kaggle/working/layoutlm-base-uncased/config.json\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:24:09.194356Z",
          "iopub.execute_input": "2021-12-12T11:24:09.194691Z",
          "iopub.status.idle": "2021-12-12T11:24:09.879011Z",
          "shell.execute_reply.started": "2021-12-12T11:24:09.194659Z",
          "shell.execute_reply": "2021-12-12T11:24:09.878033Z"
        },
        "trusted": true,
        "id": "JgQkZnBxUcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /kaggle/working/dataset/cached*"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:24:09.881937Z",
          "iopub.execute_input": "2021-12-12T11:24:09.882539Z",
          "iopub.status.idle": "2021-12-12T11:24:10.566111Z",
          "shell.execute_reply.started": "2021-12-12T11:24:09.882494Z",
          "shell.execute_reply": "2021-12-12T11:24:10.565034Z"
        },
        "trusted": true,
        "id": "eb0jLC_BUcCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python run_seq_labeling.py \\\n",
        "                            --data_dir /kaggle/working/dataset \\\n",
        "                            --labels /kaggle/working/dataset/labels.txt \\\n",
        "                            --model_name_or_path \"{pretrained_model_folder}\" \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_lower_case \\\n",
        "                            --do_train \\\n",
        "                            --num_train_epochs 10 \\\n",
        "                            --logging_steps 50 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output \\\n",
        "                            --overwrite_output_dir \\\n",
        "                            --per_gpu_train_batch_size 8 \\\n",
        "                            --per_gpu_eval_batch_size 16"
      ],
      "metadata": {
        "scrolled": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-12-12T11:24:13.027768Z",
          "iopub.execute_input": "2021-12-12T11:24:13.028114Z",
          "iopub.status.idle": "2021-12-12T11:30:53.727314Z",
          "shell.execute_reply.started": "2021-12-12T11:24:13.028075Z",
          "shell.execute_reply": "2021-12-12T11:30:53.726468Z"
        },
        "trusted": true,
        "id": "hpXQjiEcUcCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting"
      ],
      "metadata": {
        "id": "_z5Z18IsUcCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate for test set and make predictions\n",
        "! python run_seq_labeling.py \\\n",
        "                            --data_dir /kaggle/working/dataset \\\n",
        "                            --labels /kaggle/working/dataset/labels.txt \\\n",
        "                            --model_name_or_path \"{pretrained_model_folder}\" \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_predict \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output \\\n",
        "                            --per_gpu_eval_batch_size 8"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:30:53.729895Z",
          "iopub.execute_input": "2021-12-12T11:30:53.730431Z",
          "iopub.status.idle": "2021-12-12T11:31:25.024787Z",
          "shell.execute_reply.started": "2021-12-12T11:30:53.730391Z",
          "shell.execute_reply": "2021-12-12T11:31:25.023708Z"
        },
        "trusted": true,
        "id": "Fp3hMsaDUcCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat output/test_results.txt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:31:25.026448Z",
          "iopub.execute_input": "2021-12-12T11:31:25.026812Z",
          "iopub.status.idle": "2021-12-12T11:31:25.712338Z",
          "shell.execute_reply.started": "2021-12-12T11:31:25.026772Z",
          "shell.execute_reply": "2021-12-12T11:31:25.711538Z"
        },
        "trusted": true,
        "id": "g8OAg_M2UcCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mẫu kết quả\n",
        "Ví dụ cho thấy hai hình ảnh cạnh nhau của cùng một biên lai, trong đó các hộp màu là các đường được dán nhãn. Bên trái là * gốc *, vì vậy dữ liệu chúng tôi đã gắn nhãn và bên phải là dự đoán của mô hình."
      ],
      "metadata": {
        "id": "t7KNpalBUcCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot, patches\n",
        "import matplotlib\n",
        "\n",
        "data = pd.read_csv(\"/kaggle/working/dataset/test_image.txt\", delimiter=\"\\t\", names=[\"name\", \"bbox\", \"size\", \"image\"])\n",
        "data_category = pd.read_csv(\"/kaggle/working/dataset/test.txt\", delimiter=\"\\t\", names=[\"name\", \"true_category\"]).drop(columns=[\"name\"])\n",
        "data_prediction_category = pd.read_csv(\"output/test_predictions.txt\", delimiter=\" \", names=[\"name\", \"prediction_category\"]).drop(columns=[\"name\"])\n",
        "\n",
        "data_merge = data.merge(data_category, left_index=True, right_index=True)\n",
        "merged = data_merge.merge(data_prediction_category, left_index=True, right_index=True)\n",
        "merged_groups = list(merged.groupby(\"image\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:31:25.71388Z",
          "iopub.execute_input": "2021-12-12T11:31:25.714137Z",
          "iopub.status.idle": "2021-12-12T11:31:25.830404Z",
          "shell.execute_reply.started": "2021-12-12T11:31:25.714111Z",
          "shell.execute_reply": "2021-12-12T11:31:25.829677Z"
        },
        "trusted": true,
        "id": "Dd9j6mM3UcCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_prediction(data, file):\n",
        "  colors = {\n",
        "      \"S-TOTAL\": (255,0,0),\n",
        "      \"S-DATE\": (0,255,0),\n",
        "      \"S-ADDRESS\": (0,0, 255),\n",
        "      \"S-COMPANY\": (255,255,0),\n",
        "      \"O\": (192,192,192)\n",
        "  }\n",
        "\n",
        "\n",
        "  imagename = data[0].split(\".\")[0] + \".jpg\"\n",
        "  print(\"Filename:\",imagename)\n",
        "  image_path = str(sroie_folder_path / 'test' / 'img' / imagename)\n",
        "\n",
        "  img=cv2.imread(image_path)\n",
        "  img_prediction=cv2.imread(image_path)\n",
        "\n",
        "  data = data[1]\n",
        "  for bbox, category, prediction_category in zip(data['bbox'], data['true_category'], data['prediction_category']):\n",
        "    (x1, y1, x2, y2) = [int(coordinate) for coordinate in bbox.split()]\n",
        "\n",
        "    img_prediction = cv2.rectangle(img_prediction, (x1, y1), (x2, y2), colors[prediction_category], 2 if \"O\" in prediction_category else 4)\n",
        "    img = cv2.rectangle(img, (x1, y1), (x2, y2), colors[category], 2 if \"O\" in category else 4)\n",
        "\n",
        "  matplotlib.rcParams['figure.figsize'] = 15 ,18\n",
        "\n",
        "  cv2.imwrite(\"prediction.jpg\", img_prediction)\n",
        "\n",
        "  # Plot\n",
        "  fig, ax = matplotlib.pyplot.subplots(1,2)\n",
        "  ax[0].set_title(\"Original\", fontsize= 30)\n",
        "  ax[0].imshow(img);\n",
        "  ax[1].set_title(\"Prediction\", fontsize= 30)\n",
        "  ax[1].imshow(img_prediction);\n",
        "\n",
        "  # Legend\n",
        "  handles = [\n",
        "      patches.Patch(color='yellow', label='Company'),\n",
        "      patches.Patch(color='blue', label='Address'),\n",
        "      patches.Patch(color='green', label='Date'),\n",
        "      patches.Patch(color='red', label='Total'),\n",
        "      patches.Patch(color='gray', label='Other')\n",
        "  ]\n",
        "\n",
        "  fig.legend(handles=handles, prop={'size': 25}, loc='lower center')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:31:25.832833Z",
          "iopub.execute_input": "2021-12-12T11:31:25.833184Z",
          "iopub.status.idle": "2021-12-12T11:31:25.845047Z",
          "shell.execute_reply.started": "2021-12-12T11:31:25.833149Z",
          "shell.execute_reply": "2021-12-12T11:31:25.844041Z"
        },
        "trusted": true,
        "id": "FHhpPedQUcCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đây là một ví dụ khi quá trình xử lý trước của tôi không hoàn hảo, nhưng mô hình vẫn dự đoán kết quả chính xác. Từ đó, chúng ta có thể thấy rằng nếu quá trình xử lý trước của tôi tốt hơn, thì mô hình sẽ có điểm chính xác tốt hơn."
      ],
      "metadata": {
        "id": "mVgCno1LUcCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_prediction(merged_groups[0], 'test')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:31:25.846769Z",
          "iopub.execute_input": "2021-12-12T11:31:25.847283Z",
          "iopub.status.idle": "2021-12-12T11:31:26.667221Z",
          "shell.execute_reply.started": "2021-12-12T11:31:25.847225Z",
          "shell.execute_reply": "2021-12-12T11:31:26.666204Z"
        },
        "trusted": true,
        "id": "bNg5W7gzUcCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_prediction(merged_groups[34], 'test')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-12T11:31:26.668632Z",
          "iopub.execute_input": "2021-12-12T11:31:26.669156Z",
          "iopub.status.idle": "2021-12-12T11:31:27.402157Z",
          "shell.execute_reply.started": "2021-12-12T11:31:26.669118Z",
          "shell.execute_reply": "2021-12-12T11:31:27.401205Z"
        },
        "trusted": true,
        "id": "3eafEGvBUcCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}